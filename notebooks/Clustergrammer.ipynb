{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustergrammer heatmap\n",
    "\n",
    "#### This notebooks generate the json files needed to plot the clustergrammer heatmap\n",
    "\n",
    "Author: [Daniel Domingo-Fern√°ndez](https://github.com/ddomingof) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from clustergrammer import Network\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import itertools as itt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri Feb 16 13:30:26 2018'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.asctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.5 (default, Dec 11 2017, 14:22:24) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-16)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define location of gene set files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_PATH = os.environ['COMPATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kegg_excel = os.path.join(BASE_PATH,'src','compath','static','resources','excel','kegg_gene_sets.csv')\n",
    "reactome_excel= os.path.join(BASE_PATH,'src','compath','static','resources','excel','reactome_gene_sets.csv')\n",
    "wikipathways_excel = os.path.join(BASE_PATH,'src','compath','static','resources','excel','wikipathways_gene_sets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pathway_gene_set_dict(dataframe):\n",
    "    \"\"\"Creates a pathway genes dictionary\n",
    "    \n",
    "    :param pandas.DataFrame dataset: gene sets df\n",
    "    :rtype: collections.defaultdict\n",
    "    :returns: dictionary of pathway gene sets\n",
    "    \"\"\"\n",
    "    \n",
    "    pathway_dictionary = defaultdict(set)\n",
    "    \n",
    "    for pathway_name in dataframe: # iterate over columns in dataframe\n",
    "\n",
    "        for gene in dataframe[pathway_name].unique():\n",
    "            if not isinstance(gene, str): # There are NaN in the Pandas nArray\n",
    "                continue\n",
    "\n",
    "            pathway_dictionary[pathway_name].add(gene)\n",
    "            \n",
    "    return pathway_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load KEGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kegg_dataframe = pd.read_csv(kegg_excel, dtype=object)\n",
    "\n",
    "# Remove the 'Homo sapiens' out of the KEGG pathways\n",
    "kegg_dataframe.columns = [\n",
    "    kegg_pathway.replace(' - Homo sapiens (human)', '')\n",
    "    for kegg_pathway in kegg_dataframe\n",
    "] \n",
    "\n",
    "kegg_pathways = create_pathway_gene_set_dict(kegg_dataframe)\n",
    "        \n",
    "assert (len(kegg_pathways.keys()) == 323)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Reactome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reactome_dataframe = pd.read_csv(reactome_excel, dtype=object)\n",
    "\n",
    "reactome_pathways = create_pathway_gene_set_dict(reactome_dataframe)\n",
    "\n",
    "assert (len(reactome_pathways.keys()) == 2132) # Total of 2636 of those: 2132 are not empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load WikiPathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wikipathways_dataframe = pd.read_csv(wikipathways_excel, dtype=object)\n",
    "\n",
    "wikipathways_pathways = create_pathway_gene_set_dict(wikipathways_dataframe)\n",
    "\n",
    "assert (len(wikipathways_pathways.keys()) == 408)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_similarity_matrix(dataset):\n",
    "    \"\"\"Creates a similarity matrix for a given pathway-geneset dataset\n",
    "    \n",
    "    :param dict dataset: pathway gene set dictionary\n",
    "    :rtype: pandas.DataFrame\n",
    "    :returns: similarity matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    index = sorted(dataset.keys())\n",
    "    similarity_dataframe = pd.DataFrame(0.0, index=index, columns=index)\n",
    "    \n",
    "    for pathway_1, pathway_2 in itt.product(index, index):\n",
    "\n",
    "        intersection = len(dataset[pathway_1].intersection(dataset[pathway_2]))\n",
    "        smaller_set = min(len(dataset[pathway_1]), len(dataset[pathway_2]))\n",
    "                \n",
    "        similarity = float(intersection/smaller_set) # Formula to calculate similarity\n",
    "            \n",
    "        similarity_dataframe[pathway_1][pathway_2] = similarity\n",
    "        \n",
    "    return similarity_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kegg_similarity_matirx = create_similarity_matrix(kegg_pathways)\n",
    "# reactome_similarity_matirx = create_similarity_matrix(reactome_pathways)\n",
    "# wikipathways_similarity_matirx = create_similarity_matrix(wikipathways_pathways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.load_df(kegg_similarity_matirx)\n",
    "\n",
    "# Z-score normalize the rows\n",
    "net.normalize(axis='row', norm_type='zscore', keep_orig=True)\n",
    "\n",
    "# filter for the top 100 columns based on their absolute value sum\n",
    "net.filter_N_top('col', 100, 'sum')\n",
    "\n",
    "net.cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save visualization JSON to file for use by front end\n",
    "net.write_json_to_file('viz', 'kegg_clustergrammer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
